{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c464e8c4-73b4-45cd-9fee-5312f33beb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c923e1a5-e078-4ca6-b45c-4c9a109a6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2189f588-1dc1-4492-8126-8b08a8ef2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(1) # using cuda:1\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"INFO: gpu memory occupied: {info.used // 1024 ** 2} MB\")\n",
    "\n",
    "def initialize_gpu_environment():\n",
    "    torch.cuda.set_device(device)\n",
    "    print(f\"INFO: gpu environment set to {torch.cuda.current_device()}\")\n",
    "    print(f\"INFO: device name {torch.cuda.get_device_name()}\")\n",
    "    print(f\"INFO: device capability {torch.cuda.get_device_capability()}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "def cleanup_the_mess():\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    try: \n",
    "        del model\n",
    "    except NameError as e:\n",
    "        print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ccaef7-d3e0-4c1e-b6c5-0491065069c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-2b-it\"\n",
    "models_dir = \"/data/sumanth/models\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b655501a-a921-4307-af9d-702cc4bb1cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f7bdad93d4414cb63f572e222d03cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{models_dir}/{model_id}\", token=os.environ['HUGGING_FACE_TOKEN'])\n",
    "model = AutoModelForCausalLM.from_pretrained(f\"{models_dir}/{model_id}\", quantization_config=bnb_config, device_map=\"auto\", token=os.environ['HUGGING_FACE_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a25d901e-5e8c-4100-b902-28a829c248e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote: Imagination is more than just a dream. It's the blueprint for a better future.\" - Buck Brann\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Quote: Imagination is more\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2201da4-4069-4cb4-a427-d61e5da412eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592a4b4f9f034acc8cc0fa12ceebc948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1b9eda8b4e46898ea1c07e81776490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8734fc0f30364c39b85e50f6bc564f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18c82dd9a71404194334f732b94d9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=\"../utils/testrun.jsonl\")\n",
    "data = data.map(lambda samples: tokenizer(samples[\"response\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e69a22c7-116c-4aeb-b607-5381b5137998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system_prompt', 'question', 'response', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 91\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19350ff9-b0d5-45af-a14a-9013ddac5374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:21, Epoch 16/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.442100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.116200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.922700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.747800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.534700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.545100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.171700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.091100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.087600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.875700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=1.4931232810020447, metrics={'train_runtime': 22.3928, 'train_samples_per_second': 3.573, 'train_steps_per_second': 0.893, 'total_flos': 978955586764800.0, 'train_loss': 1.4931232810020447, 'epoch': 16.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "\n",
    "def formatting_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example)):\n",
    "        text = f\"\"\"<start_of_turn>user\n",
    "        {example['system_prompt'][i]} {example['question'][i]}<end_of_turn>\n",
    "        <start_of_turn>model\n",
    "        {example['response'][i]}<end_of_turn>\n",
    "        \"\"\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=2,\n",
    "        max_steps=20,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formatting_func,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f8bf96f-1dcc-4401-864a-f38fc640e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the prompt files\n",
    "SYSTEM_PROMPT = \"../prompts/zeroshot-oss-vanilla-system-prompt.txt\"\n",
    "USER_PROMPT = \"../prompts/zeroshot-vanilla-user-prompt-template.txt\"\n",
    "\n",
    "system_prompt = str()\n",
    "with open(SYSTEM_PROMPT, \"r\") as file:\n",
    "  system_prompt = file.read()\n",
    "\n",
    "user_prompt = str()\n",
    "with open(USER_PROMPT, \"r\") as file:\n",
    "  user_prompt = file.read()\n",
    "\n",
    "topics = \"\"\"\n",
    "- Logistic Regression\n",
    "- The sigmoid function\n",
    "- Classification with Logistic Regression\n",
    "- Multinomial logistic regression\n",
    "\"\"\"\n",
    "\n",
    "user_prompt += topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "702c7f09-917c-477c-84c6-fde234e82cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create a multiple choice question (MCQ) and solution that covers one or more of the following topics:\\n\\n- Logistic Regression\\n- The sigmoid function\\n- Classification with Logistic Regression\\n- Multinomial logistic regression\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f075ff14-ea06-402e-b76f-60d65b8e8489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "        You are a lecturer for an advanced undergraduate natural language processing course.\n",
      "Your goal is to create a multiple choice exam question that comprehensively evaluates\n",
      "students' understanding of natural language processing concepts,\n",
      "their ability to apply theoretical knowledge to practical situations,\n",
      "and their capacity for critical analysis and problem-solving in complex scenarios.\n",
      "\n",
      "The source textbook for this course is \"Speech and Language Processing\" (3rd ed., 2022)\n",
      "by Dan Jurafsky and James H. Martin. However, the questions should go beyond the scope\n",
      "of the textbook and require a synthesis of ideas from various sources, including research\n",
      "papers, lectures, and other supplementary materials covered in the course.\n",
      "\n",
      "For each question, you should:\n",
      "- Provide a detailed solution that explains the thought process, reasoning,\n",
      "  and step-by-step approach required to arrive at the correct answer.\n",
      "- The solution should demonstrate a deep understanding of the underlying\n",
      "  concepts and their practical applications.\n",
      "\n",
      "The question itself should meet the following criteria:\n",
      "- Be a multiple choice question (MCQ) with 5 choices in markdown format:\n",
      "  1. Choice 1\n",
      "  2. Choice 2\n",
      "  3. Choice 3\n",
      "  4. Choice 4\n",
      "  5. Choice 5\n",
      "\n",
      "- Incorporate both theoretical concepts and practical applications of natural language\n",
      "  processing topics covered in the course.\n",
      "\n",
      "- Be of a high difficulty level, challenging students to apply their knowledge in novel\n",
      "  and complex scenarios, rather than relying on rote memorization or simple recall.\n",
      "\n",
      "- Require a unique synthesis of ideas from multiple topics, concepts, and sources,\n",
      "  going beyond questions commonly found in standard textbooks.\n",
      "\n",
      "- Have choices that are challenging and non-obvious, making the correct answer difficult\n",
      "  to deduce without a deep understanding of the concepts and their practical implications.\n",
      "\n",
      "- Your output should only be in markdown format, with the following headers:\n",
      "  ## Problem Statement\n",
      "  ## Choices\n",
      "  ## Solution\n",
      "  ## Reasoning\n",
      "\n",
      "- If there are inline equations, use the markdown format: $a = b + c$\n",
      "- If there are block equations, use the markdown format: $$a = b + c$$\n",
      " Create a multiple choice question (MCQ) and solution that covers one or more of the following topics:\n",
      "\n",
      "- Logistic Regression\n",
      "- The sigmoid function\n",
      "- Classification with Logistic Regression\n",
      "- Multinomial logistic regression\n",
      "\n",
      "        model\n",
      "        ## Question Statement\n",
      "        You have a dataset of 100,000 loan applications, where the dependent\n",
      "  variable is binary (approved or declined). The features in the dataset include:\n",
      "\n",
      "  - Income\n",
      "  - Education\n",
      "  - Credit history\n",
      "  - Loan amount\n",
      "  - Gender\n",
      "  - Number of people living in household\n",
      "\n",
      "  Your task is to create a logistic regression model to predict loan approval based on these features.\n",
      "\n",
      "        ## Choices\n",
      "        1. Multinomial logistic regression would be more suitable for this dataset,\n",
      "         since it involves more than two target classes.\n",
      "2. The sigmoid function's derivative can be used to determine the optimal\n",
      "  threshold for classification.\n",
      "3. Logistic regression is particularly good for high-dimensional datasets,\n",
      "   where every feature could potentially be a relevant predictor.\n",
      "4. Regularization can be used to prevent overfitting, even in\n",
      "    a dataset that is relatively small.\n",
      "5. The logit function creates a continuous output, which can be used in a\n",
      "   classification context.\n",
      "\n",
      "        ## Solution\n",
      "        The correct solution to this question is:\n",
      "        1. Multinomial logistic regression would be more suitable for this dataset.\n",
      "        2. The sigmoid function's derivative can be used to determine the optimal\n",
      "   threshold for classification.\n",
      "        3. Logistic regression is particularly good for high-dimensional datasets,\n",
      "       where every feature could potentially be a relevant predictor.\n",
      "        4. Regularization can be used to prevent overfitting, even in a dataset that is\n",
      "           relatively small.\n",
      "        5. The logit function creates a continuous output, which can be used in a\n",
      "   classification context.\n",
      "\n",
      "        ## Reasoning\n",
      "        The key reasoning behind the correct answer lies with the nature\n",
      "        of the dataset and the predictive task at hand. Logistic regression\n",
      "        handles multiple-class problems with high-dimensional data,\n",
      "        using the logit function to model the linear boundary between\n",
      "         different categories. Here, the concept of class imbalance,\n",
      "        which violates the independence assumption of linear models, plays\n",
      "        an important role. The high dimensionality of the feature\n",
      "        sets poses a challenge, as each attribute's contribution to the\n",
      "        overall model becomes less clear. In this scenario, the advantages\n",
      "        of regularizations like L1 or L2 penalties come to the forefront.\n",
      "\n",
      "        Firstly, multi-category classification scenarios like this one\n",
      "         often suffer from class imbalance and heteroscedasticity,\n",
      "         causing the simple majority algorithms (like logistic regression) to struggle.\n",
      "         Adding complexities by creating and employing regularizations can\n",
      "         optimize the solution beyond simple logistic regression, with\n",
      "         high accuracy achieved by the logit model overall.\n",
      "\n",
      "        Secondly, the high dimensionality can lead to the phenomenon\n",
      "        of collinear features which do not contribute to the model.\n",
      "         Logistic regression's dual nature enables it to address the\n",
      "         curse of dimensionality by penalizing attributes that don't\n",
      "         impact the prediction as much. In high-dimensional datasets,\n",
      "         it is more likely to use all features by picking the top-k\n",
      "         features that have greatest impact, maximizing its value in\n",
      "         the feature selection process. Notably, the logit function\n",
      "         preserves the linear separability of the features, which plays\n",
      "          a central role in the feature selection. In spite of the top-k\n",
      "          approach, the logit function outputs a crisp, binary prediction\n",
      "          without the need for thresholding, thus simplifying the\n",
      "          classification process.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"<start_of_turn>user\n",
    "        {system_prompt} {user_prompt}<end_of_turn>\n",
    "        <start_of_turn>model\n",
    "        \"\"\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=4096, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796943bb-2aa1-4b57-9e9c-d36784c2b2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
