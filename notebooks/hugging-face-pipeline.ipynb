{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bda19eb-7bee-4ce3-8042-6b7dd557a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "models_dir = \"/data/sumanth/models\"\n",
    "device = \"cuda:1\"\n",
    "\n",
    "model_id = \"google/gemma-7b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a26bf8-1008-4eab-94d8-7c3cd7b4c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(1) # using cuda:1\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"INFO: gpu memory occupied: {info.used // 1024 ** 2} MB\")\n",
    "\n",
    "def initialize_gpu_environment():\n",
    "    torch.cuda.set_device(device)\n",
    "    print(f\"INFO: gpu environment set to {torch.cuda.current_device()}\")\n",
    "    print(f\"INFO: device name {torch.cuda.get_device_name()}\")\n",
    "    print(f\"INFO: device capability {torch.cuda.get_device_capability()}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "def cleanup_the_mess():\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    try: \n",
    "        del model\n",
    "    except NameError as e:\n",
    "        print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b23014f8-4633-495c-8159-6943a0d93c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: gpu environment set to 1\n",
      "INFO: device name NVIDIA L40\n",
      "INFO: device capability (8, 9)\n",
      "INFO: gpu memory occupied: 2006 MB\n"
     ]
    }
   ],
   "source": [
    "initialize_gpu_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c04aad-4c46-4823-bd8d-3f704e5d45c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3913e482a9b44be1902573e9a666191a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f\"{models_dir}/{model_id}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(f\"{models_dir}/{model_id}\", device_map=device)\n",
    "\n",
    "input_text = \"Give me a mutliple choice question on NLP for advanced undergraduate students.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2946e557-1736-47ea-a3a7-b50bc5ccade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Give me a mutliple choice question on NLP for advanced undergraduate students.\n",
      "\n",
      "Sure, here is the question:\n",
      "\n",
      "In NLP, which technique is commonly used to identify the sentiment of a text document?\n",
      "\n",
      "a) Lexical Analysis\n",
      "b) Part-of-Speech Tagging\n",
      "c) Named Entity Recognition\n",
      "d) Sentiment Analysis\n",
      "\n",
      "The answer is d) Sentiment Analysis.<eos>\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**input_ids, max_length=1000)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b3c15-8a98-4f9e-a9fb-b9c744c62033",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a friendly chatbot assistant that responds conversationally to users' questions.\n",
    "Keep the answers short, unless specifically asked by the user to elaborate on something.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9649759-9805-40e0-a215-c690f884ef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: cannot access local variable 'model' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "cleanup_the_mess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33264f2-9d80-4600-8a14-8c17e2f362f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cfdf39-2111-4a09-aa6d-fa562d90f48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
