{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "315bc14f-67c1-47ca-825b-6358771844a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c90cb3b-177d-4f1b-bf87-400c24e83e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL = \"llama2\"\n",
    "\n",
    "SYSTEM_PROMPT = \"../prompts/zeroshot-vanilla-system-prompt.txt\"\n",
    "USER_PROMPT = \"../prompts/zeroshot-vanilla-user-prompt.txt\"\n",
    "\n",
    "# TEMPERATURE = 1.0\n",
    "TOP_P = 0.9\n",
    "MAX_TOKENS = 4096\n",
    "\n",
    "RESPONSE = lambda timestamp: f\"../responsebuffers/zeroshot-vanilla-llama2-13b/test/{timestamp}.md\"\n",
    "\n",
    "# read in the prompt files\n",
    "system_prompt = str()\n",
    "with open(SYSTEM_PROMPT, \"r\") as file:\n",
    "  system_prompt = file.read()\n",
    "\n",
    "user_prompt = str()\n",
    "with open(USER_PROMPT, \"r\") as file:\n",
    "  user_prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de7f5d5e-7df5-4a70-893c-05cb370eb9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelfile='''\n",
    "FROM llama2:13b\n",
    "TEMPLATE \"\"\"[INST] <<SYS>>{{ .System }}<</SYS>>\n",
    "\n",
    "{{ .Prompt }} [/INST]\n",
    "\"\"\"\n",
    "PARAMETER stop \"[INST]\"\n",
    "PARAMETER stop \"[/INST]\"\n",
    "PARAMETER stop \"<<SYS>>\"\n",
    "PARAMETER stop \"<</SYS>>\"\n",
    "PARAMETER top_p 0.9\n",
    "PARAMETER top_k 100\n",
    "PARAMETER num_gpu 1\n",
    "PARAMETER main_gpu 1\n",
    "'''\n",
    "\n",
    "ollama.create(\"llama2q:13b\", modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75517049-2c39-413c-bbb2-018d52d4205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ## Question\n",
      "  A company wants to classify its customers into one of four categories based on their buying behavior: frequent, occasional, rare, and never. Using logistic regression, the company builds a model with the feature vector (age, income, education) to predict the probability of belonging to each category. However, the model's performance is not satisfactory.\n",
      "\n",
      "Which of the following could be the reason for this poor performance?\n",
      "  1. The model is overfitting due to high bias in the data.\n",
      "  2. The feature vector does not capture the underlying patterns in the data.\n",
      "  3. The learning rate is too high, causing the model to converge too quickly.\n",
      "  4. The model is underfitting due to too much noise in the data.\n",
      "  5. The cross-entropy loss function is not appropriate for this problem.\n",
      "\n",
      "## Solution\n",
      "\n",
      "The correct answer is 2: The feature vector does not capture the underlying patterns in the data.\n",
      "\n",
      "Logistic regression is a popular machine learning algorithm for classification problems. In this case, the company has built a model with a feature vector (age, income, education) to predict the probability of belonging to one of four categories based on customer buying behavior. However, if the feature vector does not capture the underlying patterns in the data, the model's performance will be poor.\n",
      "\n",
      "To improve the model's performance, the company could consider adding more relevant features or transforming the existing features to better capture the underlying patterns in the data. For example, the company could add demographic information such as gender, location, or purchase history to the feature vector. Alternatively, the company could use techniques such as principal component analysis (PCA) or singular value decomposition (SVD) to reduce the dimensionality of the feature vector and identify the most important features.\n",
      "\n",
      "The other options are not correct explanations for the poor model performance:\n",
      "\n",
      "1. Overfitting occurs when a model is too complex and learns the noise in the training data, resulting in poor generalization performance on new data. However, this does not seem to be the case here since the model's performance is not satisfactory even on the training data.\n",
      "2. The cross-entropy loss function is appropriate for classification problems like this one, so it is not the cause of the poor model performance.\n",
      "3. A high learning rate can cause the model to converge too quickly and result in overfitting, but this does not seem to be the case here since the model's performance is not satisfactory even on the training data.\n",
      "4. Underfitting occurs when a model is too simple and cannot capture the underlying patterns in the data, resulting in poor performance on both the training and new data. However, this does not seem to be the case here since the feature vector includes three relevant variables.\n",
      "\n",
      "## Correct Answer\n",
      "\n",
      "The correct answer is 2: The feature vector does not capture the underlying patterns in the data.\n",
      "\n",
      "## Reasoning\n",
      "\n",
      "To arrive at the correct answer, we need to consider the given information and the goals of the problem. The company has built a model with a feature vector (age, income, education) to predict the probability of belonging to one of four categories based on customer buying behavior. However, the model's performance is not satisfactory, indicating that the feature vector may not capture the underlying patterns in the data.\n",
      "\n",
      "The other options are not correct explanations for the poor model performance:\n",
      "\n",
      "1. Overfitting occurs when a model is too complex and learns the noise in the training data, resulting in poor generalization performance on new data. However, this does not seem to be the case here since the model's performance is not satisfactory even on the training data.\n",
      "2. The cross-entropy loss function is appropriate for classification problems like this one, so it is not the cause of the poor model performance.\n",
      "3. A high learning rate can cause the model to converge too quickly and result in overfitting, but this does not seem to be the case here since the model's performance is not satisfactory even on the training data.\n",
      "4. Underfitting occurs when a model is too simple and cannot capture the underlying patterns in the data, resulting in poor performance on both the training and new data. However, this does not seem to be the case here since the feature vector includes three relevant variables.\n",
      "\n",
      "Therefore, the correct answer is 2: The feature vector does not capture the underlying patterns in the data. This suggests that the company should consider adding more relevant features or transforming the existing features to better capture the underlying patterns in the data.\n",
      "response written to file ../responsebuffers/zeroshot-vanilla-llama2-13b/test/2024-03-17 2212.md\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": system_prompt\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": user_prompt\n",
    "    },\n",
    "]\n",
    "\n",
    "response = ollama.chat(model=\"llama2q:13b\", messages=messages)\n",
    "response = str(response[\"message\"][\"content\"])\n",
    "response_file = RESPONSE(datetime.now().strftime(\"%Y-%m-%d %H%M\"))\n",
    "\n",
    "print(response)\n",
    "\n",
    "with open(response_file, \"w+\") as file:\n",
    "  file.write(response)\n",
    "\n",
    "print(f\"response written to file {response_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300bbaa8-c028-4ea7-a3b3-dde8cca2f349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
