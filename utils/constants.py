topics = {
    "01": """
    - Regular Expressions
    - Text Normalization
    - Edit Distance
    - Words
    - Corpora
    - Simple Unix Tools for Word Tokenization
    - Word Tokenization
    - Word Normalization
    - Lemmatization
    - Stemming
    - Sentence Segmentation
    """,
    "02": """
    - N-gram Language Models
    - N-Grams
    - Evaluating Language Models: Training and Test Sets
    - Evaluating Language Models: Perplexity
    - Sampling sentences from a language model
    - Generalization and Zeros
    - Smoothing
    - Huge Language Models and Stupid Backoff
    - Kneser-Ney Smoothing
    - Perplexityâ€™s Relation to Entropy
    """,
    "03": """
    - Naive Bayes Classifiers
    - Training the Naive Bayes Classifier
    - Optimizing for Sentiment Analysis
    - Naive Bayes for other text classification tasks
    - Naive Bayes as a Language Model
    - Evaluation: Precision, Recall, F-measure
    - Test sets and Cross-validation
    - Statistical Significance Testing
    - Avoiding Harms in Classification
    """,
    "04": """
    - Logistic Regression
    - The sigmoid function
    - Classification with Logistic Regression
    - Multinomial logistic regression
    - Learning in Logistic Regression
    - The cross-entropy loss function
    - Gradient Descent
    - Regularization
    - Learning in Multinomial Logistic Regression
    - Interpreting models
    - Advanced: Deriving the Gradient Equation
    """,
    "05": """
    - Vector Semantics and Embeddings
    - Lexical Semantics
    - Words and Vectors
    - Cosine for measuring similarity
    - TF-IDF: Weighing terms in the vector
    - Pointwise Mutual Information (PMI)
    - Applications of the tf-idf or PPMI vector models
    - Word2vec
    - Visualizing Embeddings
    - Semantic properties of embeddings
    - Bias and Embeddings
    - Evaluating Vector Models
    """,
    "06": """
    - Neural Networks
    - The XOR problem
    - Feed forward Neural Networks
    - Feed forward networks for NLP: Classification
    - Training Neural Nets
    - Feed forward Neural Language Modeling
    - Training the neural language model
    """,
    "07": """
    - Transformers and Large Language Models
    - The Transformer: A Self-Attention Network
    - Multi-head Attention
    - Transformer Blocks
    - The Residual Stream view of the Transformer Block
    - The input: embeddings for token and position
    - The Language Modeling Head
    - Large Language Models with Transformers
    - Large Language Models: Generation by Sampling
    - Large Language Models: Training Transformers
    - Potential Harms from Language Models
    """,
    "08": """
    - Fine-Tuning and Masked Language Models
    - Bidirectional Transformer Encoders
    - Training Bidirectional Encoders
    - Contextual Embeddings
    - Fine-Tuning Language Models
    - Advanced: Span-based Masking
    """,
    "09": """
    - Part-of-Speech Tagging
    - Named Entities and Named Entity Tagging
    - HMM Part-of-Speech Tagging
    - Conditional Random Fields (CRFs)
    - Evaluation of Named Entity Recognition
    """,
    "10": """
    - Recurrent Neural Networks
    - RNNs as Language Models
    - RNNs for other NLP tasks
    - Stacked and Bidirectional RNN architectures
    - The LSTM
    - Summary: Common RNN NLP Architectures
    - The Encoder-Decoder Model with RNNs
    """,
    "15": """
    - Constituency
    - Context-Free Grammars
    - Treebanks
    - Grammar Equivalence and Normal Form
    - Ambiguity
    - CKY Parsing: A Dynamic Programming Approach
    - Span-BasedNeuralConstituencyParsing
    - Evaluating Parsers
    - Heads and Head-Finding
    """,
    "16": """
    - Dependency Relations
    - Transition-Based Dependency Parsing
    - Graph-Based Dependency Parsing
    - Evaluation
    """,
    "17": """
    - Relation Extraction
    - Relation Extraction Algorithms
    - Extracting Events
    - Representing Time
    - Representing Aspect
    - Temporally Annotated Datasets: TimeBank
    - Automatic Temporal Analysis
    - Template Filling
    """,
    "18": """
    - Semantic Roles
    - Diathesis Alternations
    - Semantic Roles: Problems with Thematic Roles
    - The Proposition Bank
    - Frame Net
    - Semantic Role Labeling
    - Selectional Restrictions
    - Primitive Decomposition of Predicates
    """,
    "19": """
    - Defining Emotion
    - Available Sentiment and Affect Lexicons
    - Creating Affect Lexicons by Human Labeling
    - Semi-supervised Induction of Affect Lexicons
    - Supervised Learning of Word Sentiment
    - Using Lexicons for Sentiment Recognition
    - Using Lexicons for Affect Recognition
    - Lexicon-based methods for Entity-Centric Affect
    - Connotation Frames
    """,
    "20": """
    - Coreference Phenomena: Linguistic Background
    - Coreference Tasks and Datasets
    - Mention Detection
    - Architectures for Coreference Algorithms
    - Classifiers using hand-built features
    - A neural mention-ranking algorithm
    - Entity Linking
    - Evaluation of Coreference Resolution.
    - Winograd Schema problems
    - Gender Bias in Coreference
    """,
    "21": """
    - Coherence Relations
    - Discourse Structure Parsing
    - Centering and Entity-Based Coherence
    - Representation learning models for local coherence
    - Global Coherence
    """
}
