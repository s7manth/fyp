 ## Problem Statement

Consider a large N-gram language model trained on text data from various sources, including news articles, academic papers, and novels. The model uses order 3 (trigram) N-grams. After training, the developers notice that the model performs poorly on unseen data. They decide to evaluate the model's performance using perplexity and apply various techniques to improve it.

## Choices

1. To improve the language model's performance, they should:
   a) Increase the order of N-grams from 3 to 5
   b) Decrease the order of N-grams from 3 to 2
   c) Apply Kneser-Ney smoothing
   d) Use stupid backoff
   e) Implement generalization and zeros

2. Perplexity measures:
   a) The number of words in a sentence
   b) The average number of words per minute spoken by a speaker
   c) The likelihood of a model generating a given sentence
   d) The entropy of the distribution over next words
   e) The accuracy of a sentiment analysis system on a dataset

## Solution

1. To improve the language model's performance, they should:
   c) Apply Kneser-Ney smoothing

Reasoning:
The developers notice that the model performs poorly on unseen data, which suggests that it has poor generalization ability. Techniques like Kneser-Ney smoothing can be applied to improve generalization in N-gram language models by adjusting the probabilities of rare words based on their context.

2. Perplexity measures:
   c) The likelihood of a model generating a given sentence

Reasoning:
Perplexity is a measure of how well a language model predicts a given corpus or sentence. It represents the geometric average of the probability of each word in the sentence, given the preceding context. A lower perplexity score indicates better performance of the model on the given data. Perplexity can be related to entropy through the logarithmic relationship between them: lower perplexity corresponds to higher information gain or lower entropy.