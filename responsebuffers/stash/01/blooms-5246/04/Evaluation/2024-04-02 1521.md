## Question

A machine learning team is working on a news article classification system that uses a similarity-based text mining method. The articles are pre-processed, and then TF-IDF vectors are derived from the articles’ contents. The team decides to experiment with both K-Nearest Neighbors (KNN) classification and clustering algorithms to categorize the articles into predefined topics such as politics, sports, entertainment, etc. Considering the scalability of the system as it processes a large, continuously growing dataset of news articles, they evaluate the performance and computational cost of both methods.

Given the described scenario, which of the following statements BEST evaluates the suitability of using either KNN classification or clustering algorithms in terms of scalability and computational efficiency?

1. KNN classification will be more scalable and computationally efficient because it does not require the computation of centroids for the clusters.
2. Clustering algorithms might be more scalable because they can create a model that does not need to be retrained with each new article.
3. KNN classification is inherently unscalable and should not be used for large datasets because it requires storing all data points, leading to high memory usage.
4. Both KNN classification and clustering algorithms are equally scalable and computationally efficient since they both rely on distance computations between vectors.
5. Clustering can be less computationally efficient than KNN because it requires iterative reassignment of articles to clusters until convergence, which is computationally intensive for large datasets.

## Solution

To evaluate the scalability and computational efficiency of KNN classification versus clustering algorithms, we need to consider several factors inherent in their methodologies:

- **KNN Classification:** KNN is a lazy learner that stores all training instances and performs classification based on the majority vote of the K nearest instances to a new instance. Its computational cost at the classification (query) time is quite high, especially with large datasets, due to the need to compute distances from the new instance to all instances in the training set. Although there is no explicit model-building phase, which means no retraining is strictly necessary as new data points are added, this also implies that its memory usage is proportional to the dataset size, potentially making it less scalable as datasets grow.

- **Clustering Algorithms:** Clustering, such as k-means, partitions the dataset into clusters during the training phase. This involves iterative processes of assigning instances to the nearest centroid and recalculating centroids. Although this process can be computationally intensive, especially with many iterations on large datasets, once the model is built, classifying a new instance only requires measuring the distance to the existing centroids, which can be more scalable than computing distances to every instance in the dataset. Clustering models also benefit from a training phase that, once completed, does not need to include every new instance, making the system potentially more scalable by not needing to handle the full dataset directly on every classification.

Given these considerations, the option that best evaluates the suitability of using either method for scalability and computational efficiency, while considering the continuous growth of the dataset, is:

- **Option 2: Clustering algorithms might be more scalable because they can create a model that does not need to be retrained with each new article.**

This statement acknowledges that, despite the initial computational cost of clustering, the resulting model does not require retraining with every new instance and could thus handle a growing dataset more efficiently than a KNN classifier that requires distance computations with every instance in the dataset for each classification task.

## Correct Answer

2. Clustering algorithms might be more scalable because they can create a model that does not need to be retrained with each new article.

## Reasoning

The reasoning behind choosing option 2 as the correct answer lies in the nature of KNN classification and clustering algorithms like k-means concerning scalability and computational efficiency. KNN’s method of storing all data points and computing distances to all points in the dataset for each classification can become impractical as the dataset grows, both in terms of computation time and memory usage. On the other hand, once a clustering model has been trained, new articles can be classified by simply determining their nearest cluster centroid, which does not require the model to be retrained with each new article. This process can potentially make clustering more scalable and computationally efficient in handling a continuously growing dataset, especially when compared to the KNN approach, which does not easily support scalability due to the need for real-time distance computations for classification.