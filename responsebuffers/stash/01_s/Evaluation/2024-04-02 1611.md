## Question
A data science team is working on a sentiment analysis project focusing on social media comments. They encounter a mixture of English and non-English characters, URLs, email addresses, and various emoji representations within the text. The team decides to process the text data to improve their model's performance. Given the team's requirements to: 1) Remove all URLs and email addresses, 2) Retain English and non-English characters for multilingual sentiment analysis, and 3) Eliminate all emoji characters, which of the following regular expressions, when applied in order, will best achieve their preprocessing goals?

1. First, use `\S+@\S+\.\S+` to remove emails, then `[a-zA-Z\u0080-\uFFFF]+` to keep English and non-English characters, followed by `(?:http|ftp)s?://\S+\.\S+` to remove URLs.
2. Apply `(?:http|ftp)s?://\S+\.\S+` to eliminate URLs, followed by `\S+@\S+\.\S+` to discard email addresses, and finally use `[\w\-\u0080-\uFFFF]+` to retain words including non-English characters.
3. Utilize `[\u263a-\U0001f645]` to remove emoji characters first, then `\S+@\S+\.\S+` for email addresses, and `(?:http|ftp)s?://\S+\.\S+` for URLs, keeping the rest.
4. Start with `\S+@\S+\.\S+` and `(?:http|ftp)s?://\S+\.\S+` in any order to remove emails and URLs, respectively, and use `[^\w\s]` at the end to eliminate emoji characters.
5. First, use `(?:http|ftp)s?://\S+\.\S+` for URLs and `\S+@\S+\.\S+` for emails both in one step, then `[^\u263a-\U0001f645]` to filter out emoji, and end with `[\w\-\u0080-\uFFFF]+` to preserve necessary characters.

## Solution
To approach this problem systematically:

1. **Remove URLs:** A regular expression to match URLs (both http and ftp, with and without SSL) is essential. The correct pattern for this is `(?:http|ftp)s?://\S+\.\S+`, which catches URLs starting with http, https,