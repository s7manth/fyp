## Question

Given a trigram language model (words are denoted as $w$ and their position in a sentence as subscripts), we aim to estimate the probability of the word "algorithm" given its context. The context in this scenario is the bigram "a novel". This model employs Kneser-Ney smoothing, which is known for its effectiveness in handling unseen words or N-grams, making it particularly adept at dealing with sparse data situations. Assuming the following data is available:

- The count of the bigram "a novel" is 20.
- The count of the trigram "a novel algorithm" is 3.
- The total number of unique bigrams in the dataset is 5000.
- The continuation count, $\text{count}_c$, of "algorithm" (i.e., the number of unique bigrams that "algorithm" completes) is 150.
- The discount value, $d$, applied in Kneser-Ney smoothing for adjusting counts is 0.75.

Calculate the probability, $P(w_3 = \text{"algorithm"} | w_1 = \text{"a"}, w_2 = \text{"novel"})$, for the given trigram using the Kneser-Ney smoothing formula. Select the closest option:

1. 0.015
2. 0.025
3. 0.030
4. 0.050
5. 0.075

## Solution

Kneser-Ney smoothing involves adjusting raw counts and distributing probability mass to N-grams not seen in the training corpus. For a trigram model, the formula to compute the smoothed probability of the third word given the first two words in a sequence can be expressed as:

$$P_{\text{KN}}(w_3|w_1,w_2) = \frac{\max(\text{count}(w_1,w_2,w_3) - d, 0)}{\text{count}(w_1,w_2)} + \lambda(w_1,w_2) \times P_{\text{continuation}}(w_3)$$

where,
- $\text{count}(w_1,w_2,w_3)$ is the count of the trigram.
- $\text{count}(w_1,w_2)$ is the count of the bigram.
- $d$ is the discount value.
- $\lambda(w_1,w_2)$ is a normalization factor ensuring the probabilities sum to 1, calculated as $\lambda(w_1,w_2) = \frac{d}{\text{count}(w_1,w_2)} \times \{(w_1,w_2): \text{count} > 0\}$, where $\{(w_1,w_2): \text{count} > 0\}$ is the number of unique trigrams that start with $w_1, w_2$.
- $P_{\text{continuation}}(w_3)$, or the continuation probability of $w_3$, is computed as the ratio of the continuation count of $w_3$ over the total number of unique bigrams.

Given the data:
- $\text{count}(a, novel) = 20$
- $\text{count}(a, novel, algorithm) = 3$
- Total number of unique bigrams = 5000
- $\text{count}_c(\text{"algorithm"}) = 150$
- $d = 0.75$

First, calculate the numerator of the first term:

$$\max(\text{count}(a, novel, algorithm) - d, 0) = \max(3 - 0.75, 0) = 2.25$$

The first term of the smoothed probability becomes:

$$\frac{2.25}{20} = 0.1125$$

Next, calculate $P_{\text{continuation}}(\text{"algorithm"})$:

$$P_{\text{continuation}}(\text{"algorithm"}) = \frac{\text{count}_c(\text{"algorithm"})}{\text{total unique bigrams}} = \frac{150}{5000} = 0.03$$

Since the exact value of $\lambda(w_1,w_2)$ is not provided, and calculating it precisely would require additional details not given, we can estimate the smoothed probability without it for the purpose of this solution. However, recognizing that this contribution would reduce the final probability, the closest estimate from the provided choices, considering both the direct estimate from the first term and the contribution of the continuation probability, is slightly above $0.03$.

Therefore, the closest option is:

3. 0.030

## Correct Answer

3. 0.030

## Reasoning

The calculation takes into account the adjusted count of the trigram after applying the discount, normalized by the bigram count, and incorporates the concept of continuation probability from Kneser-Ney smoothing. While the exact final probability needs the $\lambda$ factor for precise normalization, given the option choices and understanding that the addition of the continuation probability would augment the base rate derived from the direct counts, the closest approximate answer is 0.030. This showcases the application of Kneser-Ney smoothing and the handling of unseen words or rare occurrences in a corpus, demonstrating a complex understanding of smoothing techniques in natural language processing.