## Question

In the context of evaluating the performance of a dependency parser, suppose you have developed a new graph-based dependency parsing algorithm. After training your model on a large, annotated corpus, you conduct an evaluation by parsing a set of sentences that the model has not seen during training. Your evaluation focuses on the attachment score, which measures the percentage of tokens in the test set that are assigned the correct head by the parser. 

You compare your algorithm's performance against a baseline transition-based dependency parser and observe that while your parser achieves a higher overall attachment score, it performs significantly worse on sentences containing prepositional phrases. Which of the following could be a plausible explanation for this specific discrepancy in performance between the two parsing models?

1. The graph-based model lacks sufficient training data to accurately learn prepositional phrase attachments, while the transition-based model uses a set of handcrafted rules for prepositions.
2. Both models are equally affected by the garden path sentences, reducing their performance on sentences with complex prepositional phrases.
3. The edge-factored scoring function used in your graph-based parser underestimates the importance of the syntactic relations within prepositional phrases, unlike the dynamic oracle in the transition-based model which adapts better to such syntactic constructs.
4. The transition-based model is inherently superior in parsing all types of syntactic constructions, including prepositional phrases, due to its sequential processing nature.
5. Your graph-based model overfits to the training data, making it less generalizable to sentences with structures that are less represented in the training set, such as complex prepositional phrases.

## Solution

To find the most plausible explanation, let's go through the options and evaluate them based on what we know about dependency parsing and the specific situation described.

1. **Lack of specific training data on prepositional phrases for the graph-based model**: This is a plausible explanation since machine learning models, including dependency parsers, require diverse training data to learn specific constructions such as prepositional phrases correctly. However, it doesn't explain why the transition-based model would perform better unless it is specified that the transition-based model uses additional resources like handcrafted rules, which is indeed mentioned here.
   
2. **Garden path sentences affecting both models equally**: Garden path sentences are tricky for humans and models alike due to their misleading structure. However, the question specifies that the graph-based model performs worse specifically on prepositional phrases, which suggests that the issue isn't about garden path sentences affecting both models equally.

3. **Edge-factored scoring underestimation**: Graph-based parsers often use scoring functions to evaluate the likelihood of a particular syntactic structure. If the scoring function undervalues relations within prepositional phrases, this could explain the discrepancy. On the other hand, transition-based parsers, especially with a dynamic oracle, can adapt more effectively to various syntactic constructs, including prepositional phrases.

4. **Inherent superiority of transition-based models**: This choice is too broad and doesn't take into account the strengths and weaknesses of each approach. Both types of models have their advantages, and superiority often depends on the specific implementation and scenario.

5. **Overfitting in the graph-based model**: Overfitting is a common issue in machine learning models, where a model performs well on training data but poorly on unseen data. This could be a plausible explanation, but it doesn't specifically address why the performance drops on prepositional phrases compared to the baseline model, unless the training data was notably lacking in complex prepositional phrases.

Based on these analyses, the most plausible explanation is **option 3**, where the scoring function used in the graph-based parser underestimates the importance of syntactic relations within prepositional phrases compared to the transition-based model's dynamic oracle, which adapts more effectively to these syntactic constructs.

## Correct Answer

3. The edge-factored scoring function used in your graph-based parser underestimates the importance of the syntactic relations within prepositional phrases, unlike the dynamic oracle in the transition-based model which adapts better to such syntactic constructs.

## Reasoning

The reasoning behind choosing option 3 is grounded in the understanding of how graph-based and transition-based dependency parsers work. Graph-based parsers rely on scoring functions to evaluate the likelihood of certain dependency structures. If these functions do not accurately capture the complexity or importance of specific syntactic relations like those within prepositional phrases, the parser may fail to correctly attach prepositional modifiers to their heads. 

On the other hand, a transition-based parser, especially one utilizing a dynamic oracle, can learn from the parsing process itself, which allows it to adapt more flexibly to complex sentence structures as it parses them. This adaptability could enable the transition-based model to handle prepositional phrases more effectively than a graph-based model with a less sophisticated understanding of syntactic nuances, explaining the observed discrepancy in performance.