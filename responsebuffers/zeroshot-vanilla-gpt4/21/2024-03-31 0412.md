## Question
Consider a natural language processing (NLP) system that aims to automatically summarize long documents. It employs a variety of models, including those for understanding discourse structure and ensuring the coherence of the generated summaries. An important aspect of the system's design is its ability to maintain both local and global coherence by incorporating representation learning models and centering theory.

Assuming the system deals with complex, multi-thematic documents, which of the following approaches is most likely to enhance the global coherence of the generated summaries while ensuring that the theme and sub-themes of the document are appropriately captured and represented?

1. Utilizing a sequence-to-sequence model that focuses solely on the semantic similarity between consecutive sentences.
2. Applying a hierarchical attention network that captures the structure of the document at different levels (sentence, paragraph, document) and emphasizes relevant information accordingly.
3. Implementing an RNN-based model with a simple attention mechanism that pays equal attention to all parts of the document regardless of their thematic significance.
4. Incorporating a centering theory-based model that focuses exclusively on local coherence by tracking entities and their transitions across sentences.
5. Adopting a bag-of-words approach to identify and retain the most frequent terms within the document, ignoring sentence and paragraph structure.

## Solution

The best approach to enhance the global coherence of generated summaries while ensuring that the theme and sub-themes of a document are appropriately captured and represented is:

**2. Applying a hierarchical attention network that captures the structure of the document at different levels (sentence, paragraph, document) and emphasizes relevant information accordingly.**

### Reasoning

Local coherence focuses on the immediate contextual relations between entities, phrases, or sentences within a text, ensuring smoothness and logical flow from one sentence to another. On the other hand, global coherence encompasses the overall structure and thematic organization of a document, connecting diverse parts of the text in a way that supports the main theme and sub-themes.

- **Option 1** emphasizes semantic similarity between consecutive sentences, which might improve local coherence but does not guarantee that the overarching theme and sub-themes are maintained throughout the summary. Sequential models can sometimes lose track of the global context as they process the document, especially in longer documents.

- **Option 2** is specifically designed to address both local and global coherence issues by understanding the hierarchical structure of documents. Hierarchical attention networks are capable of focusing on different parts of the document (sentences, paragraphs) and dynamically adjusting the importance of each part according to its relevance to the overall document theme. This makes it particularly effective for summarization tasks where maintaining thematic consistency and coherence is crucial.

- **Option 3** presents a basic attention mechanism that does not differentiate between more or less important parts of the document. While it might capture some aspects of coherence by considering the whole document, it lacks the sophistication to understand thematic structures and ensure global coherence.

- **Option 4** focuses on local coherence by tracking entity transitions across sentences, which is an aspect of centering theory. Although beneficial for generating locally coherent summaries, this approach on its own does not address the need for maintaining the global structure and hierarchical relations present in complex documents.

- **Option 5** ignores the structural and semantic relationships between parts of the text, focusing instead on term frequency. This approach is the least likely to ensure any form of coherence in the generated summaries, as it overlooks sentence and paragraph structure altogether.

Therefore, the hierarchical attention network (Option 2) is the most comprehensive and effective method among the listed options for enhancing global coherence in document summaries while also paying attention to local coherence and thematic integrity.

## Correct Answer

2. Applying a hierarchical attention network that captures the structure of the document at different levels (sentence, paragraph, document) and emphasizes relevant information accordingly.