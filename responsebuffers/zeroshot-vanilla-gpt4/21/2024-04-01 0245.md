## Question
Given a document *D* consisting of a sequence of sentences *S = [s1, s2, ..., sn]*, you are tasked with developing an NLP system to evaluate its global coherence. The system should be able to analyze the document to determine how well the sentences relate to each other across the entire document, ensuring the narrative or argumentative structure makes sense as a whole. Which of the following approaches would most effectively allow your system to assess global coherence?

1. Employ a rule-based model that applies a fixed set of syntactic patterns to identify coherence relations between sentences.
2. Utilize a pre-trained word embeddings model to compute cosine similarity between vector representations of consecutive sentences, thereby estimating local coherence.
3. Implement a transformer-based architecture, fine-tuned on a dataset of document pairs labeled for coherence, to capture long-range dependencies and the overall narrative flow.
4. Create a graph-based model where nodes represent sentences, and edges are weighted by the frequency of shared entities across sentences, to exclusively focus on entity-based coherence.
5. Apply a recurrent neural network (RNN) trained on sentence pairs within a document to sequentially predict the likelihood of coherence relations, assessing global coherence through local pairwise relations.

## Solution
To adequately assess the global coherence of a document, it is necessary to understand not only the local interactions between sentences but also the broader narrative or argumentative structure that spans the entire document. Global coherence involves capturing long-range dependencies and the overall flow of ideas, which requires a model capable of understanding the context beyond immediate sentence pairs.

1. **Rule-based models** often lack the flexibility to understand the nuances of narrative structures and may miss implicit coherence cues not covered by predefined syntactic patterns.
2. **Cosine similarity** using pre-trained word embeddings can offer insights into local coherence by measuring the semantic similarity between consecutive sentences. However, it is limited in assessing global coherence, as it does not capture long-range dependencies or the overall document structure.
3. **Transformer-based architectures**, particularly those fine-tuned on tasks relevant to coherence, are well-suited for capturing both local and global text structures. Their ability to handle long sequences makes them adept at understanding the document-wide context and narrative flow.
4. **Graph-based models** focusing solely on shared entities can highlight aspects of entity-based coherence, but this approach may overlook the broader narrative or argumentative coherence that transcends entity repetition or variation.
5. **Recurrent Neural Networks (RNNs)**, while capable of processing sequences, inherently focus more on local pairwise relations and might struggle with capturing the global coherence of longer documents due to limitations in handling long-range dependencies and the vanishing gradient problem.

Hence, a **transformer-based architecture** offers a comprehensive approach for evaluating global coherence by capturing complex dependencies and narrative structures across the whole document.

## Correct Answer
3. Implement a transformer-based architecture, fine-tuned on a dataset of document pairs labeled for coherence, to capture long-range dependencies and the overall narrative flow.

## Reasoning
Transformer-based models, particularly those that have been fine-tuned for tasks involving understanding document structure and coherence, are inherently geared towards capturing both local and global dependencies. The self-attention mechanism in transformers allows every token to interact with every other token in a sequence, regardless of their distance. This property is crucial for assessing global coherence as it enables the model to evaluate how well the parts of a document fit together into a coherent whole. When fine-tuned on a dataset specifically labeled for coherence, this model type can accurately assess the extent to which the document adheres to a logical, coherent narrative or argumentative structure, making it the most effective among the options presented.