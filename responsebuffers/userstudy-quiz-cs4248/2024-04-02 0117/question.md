A research team wants to develop a system for automatic text summarization. To this end, they plan to fine-tune a bidirectional transformer encoder, leveraging advanced techniques for improving the model's understanding of context within the text. Given the complexity of the task, which involves generating coherent and concise summaries from longer texts, the team considers incorporating span-based masking during the pre-training phase to enhance the model's ability to grasp the semantic meaning of text spans more effectively.

Which of the following describes the most likely impact of employing span-based masking on the pre-training of their bidirectional transformer encoder, especially in the context of improving its performance on the text summarization task?

1. It will significantly reduce the model's training time, as span-based masking streamlines the processing of input sequences.
2. It will improve the model's ability to understand contextual dependencies across longer spans of text, potentially leading to more coherent summaries.
3. It will mainly enhance the model's performance on token-level tasks such as named entity recognition, without notable benefits for text summarization.
4. It will degrade the model's performance due to the increased complexity introduced by handling spans of text, making it harder for the model to learn effectively.
5. It will not affect the model's summarization capabilities but will increase the model's size and memory requirements due to processing more complex structures.