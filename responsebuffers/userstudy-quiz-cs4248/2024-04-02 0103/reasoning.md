The key to this question is understanding the balance between normalizing for better word matching and preserving contextual meanings. Normalizing spelling variations directly addresses the example provided ("Email" vs. "E-mail"), ensuring that different usages of the same term are recognized as equivalent without losing their original context. Applying lowercasing further aids in matching by removing case variations as a source of discrepancy. Finally, performing word tokenization is crucial for any text processing and allows for the application of subsequent NLP techniques on a word-by-word basis. This sequence of preprocessing steps thus effectively meets the goal of enhancing word matching capabilities while being mindful of contextual nuances, especially for known variations of words within the text.