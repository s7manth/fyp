Among the presented options, the combination of stemming and text normalization most effectively targets the aim of reducing vocabulary size due to morphological variations while attempting to maintain semantic integrity to some extent. 

While stemming might be a bit more aggressive in reducing words (potentially sacrificing some semantic details), when combined with text normalization, it standardizes textual data, simplifying and reducing the number of unique tokens that the classification model needs to understand. Lemmatization would indeed be a more semantically sensitive choice compared to stemming. However, in the given options, the combination of **stemming and text normalization** directly addresses the vocabulary reduction goal with practical feasibility and applications in mind. This combination is efficient in processing large datasets commonly found in English news articles and achieves a good balance between reducing the vocabulary size and maintaining the core meaning of the text for classification purposes.