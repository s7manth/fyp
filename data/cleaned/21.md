Some day we'll be able to measure the power of words Maya Angelou In this chapter we turn to tools for interpreting **affective** meaning, extending our affective study of sentiment analysis in Chapter 4. We use the word 'affective', following the tradition in **affective computing** (Picard, 1995) to mean emotion, sentiment, personality, mood, and attitudes. Affective meaning is closely related to **subjectivity**, subjectivity the study of a speaker or writer's evaluations, opinions, emotions, and speculations (Wiebe et al., 1999).

How should affective meaning be defined? One influential typology of affective states comes from Scherer (2000), who defines each class of affective states by factors like its cognitive realization and time course (Fig. 21.1).

Emotion: Relatively brief episode of response to the evaluation of an external
or internal event as being of major significance. (*angry, sad, joyful, fearful, ashamed, proud, elated, desperate*)
Mood: Diffuse affect state, most pronounced as change in subjective feeling, of
low intensity but relatively long duration, often without apparent cause. (*cheerful, gloomy, irritable, listless, depressed, buoyant*)
Interpersonal stance: Affective stance taken toward another person in a specific interaction, coloring the interpersonal exchange in that situation. (*distant, cold, warm, supportive, contemptuous, friendly*)
Attitude: Relatively enduring, affectively colored beliefs, preferences, and predispositions towards objects or persons. (*liking, loving, hating, valuing, desiring*)
Personality traits: Emotionally laden, stable personality dispositions and behavior tendencies, typical for a person. (*nervous, anxious, reckless, morose, hostile, jealous*)

We can design extractors for each of these kinds of affective states. Chapter 4
already introduced *sentiment analysis*, the task of extracting the positive or negative orientation that a writer expresses in a text. This corresponds in Scherer's typology to the extraction of **attitudes**: figuring out what people like or dislike, from affectrich texts like consumer reviews of books or movies, newspaper editorials, or public sentiment in blogs or tweets.

Detecting **emotion** and **moods** is useful for detecting whether a student is confused, engaged, or certain when interacting with a tutorial system, whether a caller to a help line is frustrated, whether someone's blog posts or tweets indicated depression. Detecting emotions like fear in novels, for example, could help us trace what groups or situations are feared and how that changes over time.

Detecting different **interpersonal stances** can be useful when extracting information from human-human conversations. The goal here is to detect stances like friendliness or awkwardness in interviews or friendly conversations, for example for summarizing meetings or finding parts of a conversation where people are especially excited or engaged, conversational **hot spots** that can help in meeting summarization. Detecting the **personality** of a user—such as whether the user is an extrovert or the extent to which they are **open to experience**— can help improve conversational agents, which seem to work better if they match users' personality expectations (Mairesse and Walker, 2008). And affect is important for generation as well as recognition; synthesizing affect is important for conversational agents in various domains, including literacy tutors such as children's storybooks, or computer games.

In Chapter 4 we introduced the use of naive Bayes classification to classify a document's sentiment. Various classifiers have been successfully applied to many of these tasks, using all the words in the training set as input to a classifier which then determines the affect status of the text.

In this chapter we focus on an alternative model, in which instead of using every word as a feature, we focus only on certain words, ones that carry particularly strong cues to affect or sentiment. We call these lists of words affective lexicons or sentiment lexicons. These lexicons presuppose a fact about semantics: that words have affective meanings or **connotations**. The word *connotation* has different meanings connotations in different fields, but here we use it to mean the aspects of a word's meaning that are related to a writer or reader's emotions, sentiment, opinions, or evaluations. In addition to their ability to help determine the affective status of a text, connotation lexicons can be useful features for other kinds of affective tasks, and for computational social science analysis.

In the next sections we introduce basic theories of emotion, show how sentiment lexicons are a special case of emotion lexicons, and mention some useful lexicons. We then survey three ways for building lexicons: human labeling, semi-supervised, and supervised. Finally, we talk about how to detect affect toward a particular entity, and introduce connotation frames.

## 21.1 Defining Emotion

One of the most important affective classes is **emotion**, which Scherer (2000) defines emotion as a "relatively brief episode of response to the evaluation of an external or internal event as being of major significance".

Detecting emotion has the potential to improve a number of language processing tasks. Emotion recognition could help dialogue systems like tutoring systems detect that a student was unhappy, bored, hesitant, confident, and so on. Automatically detecting emotions in reviews or customer responses (anger, dissatisfaction, trust) could help businesses recognize specific problem areas or ones that are going well. Emotion can play a role in medical NLP tasks like helping diagnose depression or suicidal intent. Detecting emotions expressed toward characters in novels might play a role in understanding how different social groups were viewed by society at different times.

Computational models of emotion in NLP have mainly been based on two families of theories of emotion (out of the many studied in the field of affective science). In one of these families, emotions are viewed as fixed atomic units, limited in number, and from which others are generated, often called **basic emotions** (Tomkins basic emotions
1962, Plutchik 1962), a model dating back to Darwin. Perhaps the most well-known of this family of theories are the 6 emotions proposed by Ekman (e.g., Ekman 1999) to be universally present in all cultures: surprise, happiness, anger, fear, disgust, sadness. Another atomic theory is the Plutchik (1980) wheel of emotion, consisting of 8 basic emotions in four opposing pairs: joy–sadness, anger–fear, *trust–disgust*, and *anticipation–surprise*, together with the emotions derived from them, shown in Fig. 21.2.

The second class of emotion theories widely used in NLP views emotion as a space in 2 or 3 dimensions (Russell, 1980). Most models include the two dimensions valence and **arousal**, and many add a third, **dominance**. These can be defined as:

valence: the pleasantness of the stimulus arousal: the level of alertness, activeness, or energy provoked by the stimulus dominance: the degree of control or dominance exerted by the stimulus or the
emotion
Sentiment can be viewed as a special case of this second view of emotions as points in space. In particular, the **valence** dimension, measuring how pleasant or unpleasant a word is, is often used directly as a measure of sentiment.

In these lexicon-based models of affect, the affective meaning of a word is generally fixed, irrespective of the linguistic context in which a word is used, or the dialect or culture of the speaker. By contrast, other models in affective science represent emotions as much richer processes involving cognition (Barrett et al., 2007). In appraisal theory, for example, emotions are complex processes, in which a person considers how an event is congruent with their goals, taking into account variables like the agency, certainty, urgency, novelty and control associated with the event (Moors et al., 2013). Computational models in NLP taking into account these richer theories of emotion will likely play an important role in future work.

## 21.2 Available Sentiment And Affect Lexicons

A wide variety of affect lexicons have been created and released. The most basic lexicons label words along one dimension of semantic variability, generally called "sentiment" or "valence".

In the simplest lexicons this dimension is represented in a binary fashion, with a wordlist for positive words and a wordlist for negative words. The oldest is the General Inquirer (Stone et al., 1966), which drew on content analysis and on early General Inquirer work in the cognitive psychology of word meaning (Osgood et al., 1957). The General Inquirer has a lexicon of 1915 positive words and a lexicon of 2291 negative words (as well as other lexicons discussed below). The MPQA Subjectivity lexicon
(Wilson et al., 2005) has 2718 positive and 4912 negative words drawn from prior lexicons plus a bootstrapped list of subjective words and phrases (Riloff and Wiebe, 2003). Each entry in the lexicon is hand-labeled for sentiment and also labeled for reliability (strongly subjective or weakly subjective). The polarity lexicon of Hu and Liu (2004) gives 2006 positive and 4783 negative words, drawn from product reviews, labeled using a bootstrapping method from WordNet.

Positive
admire, amazing, assure, celebration, charm, eager, enthusiastic, excellent, fancy, fantastic, frolic, graceful, happy, joy, luck, majesty, mercy, nice, patience, perfect, proud, rejoice, relief, respect, satisfactorily, sensational, super, terrific, thank, vivid, wise, wonderful, zest
Negative abominable, anger, anxious, bad, catastrophe, cheap, complaint, condescending, deceit,
defective, disappointment, embarrass, fake, fear, filthy, fool, guilt, hate, idiot, inflict, lazy, miserable, mourn, nervous, objection, pest, plot, reject, scream, silly, terrible, unfriendly, vile, wicked

Slightly more general than these sentiment lexicons are lexicons that assign each word a value on all three affective dimensions. The NRC Valence, Arousal, and Dominance (VAD) lexicon (Mohammad, 2018a) assigns valence, arousal, and dominance scores to 20,000 words. Some examples are shown in Fig. 21.4.

|             |       |            |   Valence | Arousal     |   Dominance |
|-------------|-------|------------|-----------|-------------|-------------|
| vacation    | 0.84  | enraged    |     0.962 | powerful    |       0.991 |
| delightful  | 0.918 | party      |     0.84  | authority   |       0.935 |
| whistle     | 0.653 | organized  |     0.337 | saxophone   |       0.482 |
| consolation | 0.408 | effortless |     0.12  | discouraged |       0.009 |
| torture     | 0.115 | napping    |     0.046 | weak        |       0.045 |

The NRC Word-Emotion Association Lexicon, also called **EmoLex** (Moham-
EmoLex mad and Turney, 2013), uses the Plutchik (1980) 8 basic emotions defined above. The lexicon includes around 14,000 words including words from prior lexicons as well as frequent nouns, verbs, adverbs and adjectives. Values from the lexicon for some sample words:

trust
anger
anticipation
disgust
fear
joy
sadness
surprise
negative
positive
Word
reward
0 1
0
0
1
0 1
1 1
0
worry
0 1
0
1
0
1 0
0 0
1
tenderness 0 0
0
0
1
0 0
0 1
0
sweetheart 0 1
0
0
1
1 0
1 1
0
suddenly
0 0
0
0
0
0 1
0 0
0
thirst
0 1
0
0
0
1 1
0 0
0
garbage
0 0
1
0
0
0 0
0 0
1

For a smaller set of 5,814 words, the NRC Emotion/Affect Intensity Lexicon
(Mohammad, 2018b) contains real-valued scores of association for anger, fear, joy, and sadness; Fig. 21.5 shows examples.

|            |       |            |       | Anger    |   Fear | Joy          |   Sadness |
|------------|-------|------------|-------|----------|--------|--------------|-----------|
| outraged   | 0.964 | horror     | 0.923 | superb   |  0.864 | sad          |     0.844 |
| violence   | 0.742 | anguish    | 0.703 | cheered  |  0.773 | guilt        |     0.75  |
| coup       | 0.578 | pestilence | 0.625 | rainbow  |  0.531 | unkind       |     0.547 |
| oust       | 0.484 | stressed   | 0.531 | gesture  |  0.387 | difficulties |     0.421 |
| suspicious | 0.484 | failing    | 0.531 | warms    |  0.391 | beggar       |     0.422 |
| nurture    | 0.059 | confident  | 0.094 | hardship |  0.031 | sing         |     0.017 |

LIWC, **Linguistic Inquiry and Word Count**, is a widely used set of 73 lex-
LIWC
icons containing over 2300 words (Pennebaker et al., 2007), designed to capture aspects of lexical meaning relevant for social psychological tasks. In addition to sentiment-related lexicons like ones for negative emotion (bad, weird, hate, problem, tough) and positive emotion (*love, nice, sweet*), LIWC includes lexicons for categories like anger, sadness, cognitive mechanisms, perception, tentative, and inhibition, shown in Fig. 21.6.
There are various other hand-built affective lexicons. The General Inquirer includes additional lexicons for dimensions like strong vs. weak, active vs. passive, overstated vs. understated, as well as lexicons for categories like pleasure, pain, virtue, vice, motivation, and cognitive orientation.
Another useful feature for various tasks is the distinction between concrete
concrete
words like banana or *bathrobe* and **abstract** words like *belief* and *although*. The
abstract
lexicon in Brysbaert et al. (2014) used crowdsourcing to assign a rating from 1 to 5 of the concreteness of 40,000 words, thus assigning banana, *bathrobe*, and *bagel* 5, belief 1.19, *although* 1.07, and in between words like *brisk* a 2.5.

## 21.3 Creating Affect Lexicons By Human Labeling

The earliest method used to build affect lexicons, and still in common use, is to have humans label each word. This is now most commonly done via **crowdsourcing**:
crowdsourcing breaking the task into small pieces and distributing them to a large number of anno-

|            |          |          |            | Positive   | Negative   |
|------------|----------|----------|------------|------------|------------|
| Emotion    | Emotion  | Insight  | Inhibition | Family     | Negate     |
| appreciat* | anger*   | aware*   | avoid*     | brother*   | aren't     |
| comfort*   | bore*    | believe  | careful*   | cousin*    | cannot     |
| great      | cry      | decid*   | hesitat*   | daughter*  | didn't     |
| happy      | despair* | feel     | limit*     | family     | neither    |
| interest   | fail*    | figur*   | oppos*     | father*    | never      |
| joy*       | fear     | know     | prevent*   | grandf*    | no         |
| perfect*   | griev*   | knew     | reluctan*  | grandm*    | nobod*     |
| please*    | hate*    | means    | safe*      | husband    | none       |
| safe*      | panic*   | notice*  | stop       | mom        | nor        |
| terrific   | suffers  | recogni* | stubborn*  | mother     | nothing    |
| value      | terrify  | sense    | wait       | niece*     | nowhere    |
| wow*       | violent* | think    | wary       | wife       | without    |

tators. Let's take a look at some of the methodological choices for two crowdsourced emotion lexicons.

The NRC Emotion Lexicon (EmoLex) (Mohammad and Turney, 2013), labeled emotions in two steps. To ensure that the annotators were judging the correct sense of the word, they first answered a multiple-choice synonym question that primed the correct sense of the word (without requiring the annotator to read a potentially confusing sense definition). These were created automatically using the headwords associated with the thesaurus category of the sense in question in the Macquarie dictionary and the headwords of 3 random distractor categories. An example:

## Which Word Is Closest In Meaning (Most Related) To Startle?

- automobile - shake - honesty - entertain
For each word (e.g. *startle*), the annotator was then asked to rate how associated that word is with each of the 8 emotions (joy, fear, *anger*, etc.). The associations were rated on a scale of not, weakly, *moderately*, and *strongly* associated. Outlier ratings were removed, and then each term was assigned the class chosen by the majority of the annotators, with ties broken by choosing the stronger intensity, and then the 4 levels were mapped into a binary label for each word (no and weak mapped to 0, moderate and strong mapped to 1).

The NRC VAD Lexicon (Mohammad, 2018a) was built by selecting words and emoticons from prior lexicons and annotating them with crowd-sourcing using bestworst scaling (Louviere et al. 2015, Kiritchenko and Mohammad 2017). In bestbest-worst scaling worst scaling, annotators are given N items (usually 4) and are asked which item is the **best** (highest) and which is the **worst** (lowest) in terms of some property. The set of words used to describe the ends of the scales are taken from prior literature. For valence, for example, the raters were asked:
Q1. Which of the four words below is associated with the MOST happiness / pleasure / positiveness / satisfaction / contentedness / hopefulness OR LEAST unhappiness / annoyance / negativeness / dissatisfaction /
melancholy / despair? (Four words listed as options.)
Q2. Which of the four words below is associated with the LEAST happiness / pleasure / positiveness / satisfaction / contentedness / hopefulness OR MOST unhappiness / annoyance / negativeness / dissatisfaction / melancholy / despair? (Four words listed as options.)
The score for each word in the lexicon is the proportion of times the item was chosen as the best (highest V/A/D) minus the proportion of times the item was chosen as the worst (lowest V/A/D). The agreement between annotations are evaluated by splithalf reliability: split the corpus in half and compute the correlations between the split-half reliability annotations in the two halves.

## 21.4 Semi-Supervised Induction Of Affect Lexicons

Another common way to learn sentiment lexicons is to start from a set of seed words that define two poles of a semantic axis (words like good or *bad*), and then find ways to label each word w by its similarity to the two seed sets. Here we summarize two families of seed-based semi-supervised lexicon induction algorithms, axis-based and graph-based.

## 21.4.1 Semantic Axis Methods

One of the most well-known lexicon induction methods, the Turney and Littman (2003) algorithm, is given seed words like good or *bad*, and then for each word w to be labeled, measures both how similar it is to *good* and how different it is from *bad*. Here we describe a slight extension of the algorithm due to An et al. (2018), which is based on computing a **semantic axis**.

In the first step, we choose seed words by hand. There are two methods for dealing with the fact that the affect of a word is different in different contexts: (1) start with a single large seed lexicon and rely on the induction algorithm to fine-tune it to the domain, or (2) choose different seed words for different genres. Hellrich et al. (2019) suggests that for modeling affect across different historical time periods, starting with a large modern affect dictionary is better than small seedsets tuned to be stable across time. As an example of the second approach, Hamilton et al. (2016) define one set of seed words for general sentiment analysis, a different set for Twitter, and yet another set for sentiment in financial text:

| Domain                                      | Positive seeds   | Negative seeds   |
|---------------------------------------------|------------------|------------------|
| General                                     |                  |                  |
| good, lovely, excellent, fortunate, pleas-  |                  |                  |
| ant, delightful, perfect, loved, love,      |                  |                  |
| happy                                       |                  |                  |
| bad, horrible, poor, unfortunate, un-       |                  |                  |
| pleasant, disgusting, evil, hated, hate,    |                  |                  |
| unhappy                                     |                  |                  |
| Twitter                                     |                  |                  |
| love,                                       | loved,           | loves,           |
| amazing, best, fantastic, correct, happy    |                  |                  |
| hate, hated, hates, terrible, nasty, awful, |                  |                  |
| worst, horrible, wrong, sad                 |                  |                  |
| Finance                                     |                  |                  |
| successful, excellent, profit, beneficial,  |                  |                  |
| improving, improved, success, gains,        |                  |                  |
| positive                                    |                  |                  |
| negligent, loss, volatile, wrong, losses,   |                  |                  |
| damages, bad, litigation, failure, down,    |                  |                  |
| negative                                    |                  |                  |

In the second step, we compute embeddings for each of the pole words. These embeddings can be off-the-shelf word2vec embeddings, or can be computed directly

on a specific corpus (for example using a financial corpus if a finance lexicon is the goal), or we can fine-tune off-the-shelf embeddings to a corpus. Fine-tuning is especially important if we have a very specific genre of text but don't have enough data to train good embeddings. In fine-tuning, we begin with off-the-shelf embeddings like word2vec, and continue training them on the small target corpus.

Once we have embeddings for each pole word, we create an embedding that represents each pole by taking the centroid of the embeddings of each of the seed words; recall that the centroid is the multidimensional version of the mean. Given a set of embeddings for the positive seed words S+ = {E(w+
1 ),E(w+
2 )*,...,*E(w+
n )}, and embeddings for the negative seed words S− = {E(w−
1 ),E(w−
2 ),...,E(w−
m)}, the pole centroids are:

$$\mathbf{V}^{+}=\frac{1}{n}\sum_{1}^{n}E(w_{i}^{+})$$ $$\mathbf{V}^{-}=\frac{1}{m}\sum_{1}^{m}E(w_{i}^{-})\tag{21.1}$$
The semantic axis defined by the poles is computed just by subtracting the two vectors:

$\mathbf{V}_{\text{axis}}=\mathbf{V}^{+}-\mathbf{V}^{-}$ (21.2)
V*axis*, the semantic axis, is a vector in the direction of positive sentiment. Finally, we compute (via cosine similarity) the angle between the vector in the direction of positive sentiment and the direction of w's embedding. A higher cosine means that w is more aligned with S+ than S−.

$$\begin{array}{rcl}\mbox{score}(w)&=&\cos\left(E(w),\mbox{V}_{\mbox{axis}}\right)\\ &=&\frac{E(w)\cdot\mbox{V}_{\mbox{axis}}}{\|E(w)\|\|\mbox{V}_{\mbox{axis}}\|}\end{array}\tag{21.3}$$
If a dictionary of words with sentiment scores is sufficient, we're done! Or if we need to group words into a positive and a negative lexicon, we can use a threshold or other method to give us discrete lexicons.

## 21.4.2 Label Propagation

An alternative family of methods defines lexicons by propagating sentiment labels on graphs, an idea suggested in early work by Hatzivassiloglou and McKeown (1997). We'll describe the simple SentProp (Sentiment Propagation) algorithm of Hamilton et al. (2016), which has four steps:

1. **Define a graph**: Given word embeddings, build a weighted lexical graph by
connecting each word with its k nearest neighbors (according to cosine similarity). The weights of the edge between words wi and w j are set as:
$${\bf E}_{i,j}=\arccos\left(-\frac{{\bf w_{i}}^{\top}{\bf w_{j}}}{||{\bf w_{i}}||\,||{\bf w_{j}}||}\right).\tag{21.4}$$
2. **Define a seed set:** Choose positive and negative seed words.
3. **Propagate polarities from the seed set:** Now we perform a random walk on
this graph, starting at the seed set. In a random walk, we start at a node and then choose a node to move to with probability proportional to the edge probability. A word's polarity score for a seed set is proportional to the probability of a random walk from the seed set landing on that word (Fig. 21.7).
4. **Create word scores**: We walk from both positive and negative seed sets,
resulting in positive (rawscore+(wi)) and negative (rawscore−(wi)) raw label
scores. We then combine these values into a positive-polarity score as:
$$\text{score}^{+}(w_{i})=\frac{\text{rawscore}^{+}(w_{i})}{\text{rawscore}^{+}(w_{i})+\text{rawscore}^{-}(w_{i})}\tag{21.5}$$
It's often helpful to standardize the scores to have zero mean and unit variance within a corpus.

5. **Assign confidence to each score:** Because sentiment scores are influenced by
the seed set, we'd like to know how much the score of a word would change if a different seed set is used. We can use bootstrap sampling to get confidence regions, by computing the propagation B times over random subsets of the positive and negative seed sets (for example using B = 50 and choosing 7 of
the 10 seed words each time). The standard deviation of the bootstrap sampled polarity scores gives a confidence measure.

## 21.4.3 Other Methods

The core of semisupervised algorithms is the metric for measuring similarity with the seed words. The Turney and Littman (2003) and Hamilton et al. (2016) approaches above used embedding cosine as the distance metric: words were labeled as positive basically if their embeddings had high cosines with positive seeds and low cosines with negative seeds. Other methods have chosen other kinds of distance metrics besides embedding cosine.

For example the Hatzivassiloglou and McKeown (1997) algorithm uses syntactic cues; two adjectives are considered similar if they were frequently conjoined by and and rarely conjoined by *but*. This is based on the intuition that adjectives conjoined by the words *and* tend to have the same polarity; positive adjectives are generally coordinated with positive, negative with negative:
fair and legitimate, corrupt and brutal but less often positive adjectives coordinated with negative:
*fair and brutal, *corrupt and legitimate

By contrast, adjectives conjoined by *but* are likely to be of opposite polarity:
fair but brutal Another cue to opposite polarity comes from morphological negation (un-, *im-*,
-less). Adjectives with the same root but differing in a morphological negative (adequate/inadequate, *thoughtful/thoughtless*) tend to be of opposite polarity.

Yet another method for finding words that have a similar polarity to seed words is to make use of a thesaurus like WordNet (Kim and Hovy 2004, Hu and Liu 2004). A word's synonyms presumably share its polarity while a word's antonyms probably have the opposite polarity. After a seed lexicon is built, each lexicon is updated as follows, possibly iterated.

Lex+: Add synonyms of positive words (*well*) and antonyms (like *fine*) of negative
words
Lex−: Add synonyms of negative words (*awful*) and antonyms (like *evil*) of positive
words
An extension of this algorithm assigns polarity to WordNet senses, called Senti-
WordNet (Baccianella et al., 2010). Fig. 21.8 shows some examples.

SentiWordNet

|                                              | Synset                                                             | Pos              | Neg        |   Obj |
|----------------------------------------------|--------------------------------------------------------------------|------------------|------------|-------|
| good#6                                       | 'agreeable or pleasing'                                            | 1                | 0          |  0    |
| respectable#2 honorable#4 good#4 estimable#2 | 'deserving of esteem'                                              | 0.75             | 0          |  0.25 |
| estimable#3 computable#1                     | 'may be computed or estimated'                                     | 0                | 0          |  1    |
| sting#1 burn#4 bite#2                        | 'cause a sharp or stinging pain'                                   | 0                | 0.875 .125 |       |
| acute#6                                      | 'of critical importance and consequence'                           | 0.625 0.125 .250 |            |       |
| acute#4                                      | 'of an angle; less than 90 degrees'                                | 0                | 0          |  1    |
| acute#1                                      | 'having or experiencing a rapid onset and short but severe course' | 0                | 0.5        |  0.5  |

In this algorithm, polarity is assigned to entire synsets rather than words. A
positive lexicon is built from all the synsets associated with 7 positive words, and a negative lexicon from synsets associated with 7 negative words. A classifier is then trained from this data to take a WordNet gloss and decide if the sense being defined is positive, negative or neutral. A further step (involving a random-walk algorithm) assigns a score to each WordNet synset for its degree of positivity, negativity, and neutrality.

In summary, semisupervised algorithms use a human-defined set of seed words for the two poles of a dimension, and use similarity metrics like embedding cosine, coordination, morphology, or thesaurus structure to score words by how similar they are to the positive seeds and how dissimilar to the negative seeds.

## 21.5 Supervised Learning Of Word Sentiment

Semi-supervised methods require only minimal human supervision (in the form of seed sets). But sometimes a supervision signal exists in the world and can be made use of. One such signal is the scores associated with *online reviews*.

The web contains an enormous number of online reviews for restaurants, movies, books, or other products, each of which have the text of the review along with an associated review score: a value that may range from 1 star to 5 stars, or scoring 1
to 10. Fig. 21.9 shows samples extracted from restaurant, book, and movie reviews.

## Movie Review Excerpts (Imdb)

10 A great movie. This film is just a wonderful experience. It's surreal, zany, witty and slapstick
all at the same time. And terrific performances too.
1
This was probably the worst movie I have ever seen. The story went nowhere even though they could have done some interesting stuff with it.

## Restaurant Review Excerpts (Yelp)

5
The service was impeccable. The food was cooked and seasoned perfectly... The watermelon was perfectly square ... The grilled octopus was ... mouthwatering...
2
...it took a while to get our waters, we got our entree before our starter, and we never received
silverware or napkins until we requested them...

## Book Review Excerpts (Goodreads)

1
I am going to try and stop being deceived by eye-catching titles. I so wanted to like this book and was so disappointed by it.
5
This book is hilarious. I would recommend it to anyone looking for a satirical read with a romantic twist and a narrator that keeps butting in

## Product Review Excerpts (Amazon)

5
The lid on this blender though is probably what I like the best about it... enables you to pour into something without even taking the lid off! ... the perfect pitcher! ... works fantastic.
1
I hate this blender... It is nearly impossible to get frozen fruit and ice to turn into a smoothie... You have to add a TON of liquid. I also wish it had a spout ...
We can use this review score as supervision: positive words are more likely to appear in 5-star reviews; negative words in 1-star reviews. And instead of just a binary polarity, this kind of supervision allows us to assign a word a more complex representation of its polarity: its distribution over stars (or other scores).

Thus in a ten-star system we could represent the sentiment of each word as a
10-tuple, each number a score representing the word's association with that polarity level. This association can be a raw count, or a likelihood P(w|c), or some other function of the count, for each class c from 1 to 10.

For example, we could compute the IMDb likelihood of a word like disappoint(ed/ing) occurring in a 1 star review by dividing the number of times disappoint(ed/ing) occurs in 1-star reviews in the IMDb dataset (8,557) by the total number of words occurring in 1-star reviews (25,395,214), so the IMDb estimate of P(*disappointing*|1) is .0003.

A slight modification of this weighting, the normalized likelihood, can be used as an illuminating visualization (Potts, 2011)1

$$P(w|c)\ =\ \frac{count(w,c)}{\sum_{w\in C}count(w,c)}$$ $$PottsScore(w)\ =\ \frac{P(w|c)}{\sum_{c}P(w|c)}\tag{21.6}$$

Dividing the IMDb estimate $P(disappointing|1)$ of.0003 by the sum of the likelihood $P(w|c)$ over all categories gives a Potts score of 0.10. The word _disappointing_
thus is associated with the vector [.10, .12, .14, .14, .13, .11, .08, .06, .06, .05]. The Potts diagram (Potts, 2011) is a visualization of these word scores, representing the Potts diagram

| -0.50   | -0.39   | -0.28   |
|---------|---------|---------|

IMDB
Ca Cat^
"Potts&diagrams"
Potts,&Christopher.& 2011.&NSF&wor restructuring&adjectives.

prior sentiment of a word as a distribution over the rating categories.

Fig. 21.10 shows the Potts diagrams for 3 positive and 3 negative scalar adjectives. Note that the curve for strongly positive scalars have the shape of the letter J, while strongly negative scalars look like a reverse J. By contrast, weakly positive and negative scalars have a hump-shape, with the maximum either below the mean (weakly negative words like *disappointing*) or above the mean (weakly positive words like *good*). These shapes offer an illuminating typology of affective meaning.

Positive scalars
Negative scalars
Emphatics
Atten
totally
good
disappointing
| -0.39                         |
|-------------------------------|
| 1  2  3  4  5  6  7  8  9  10 |
| 1  2  3  4                    |
| 1  2  3  4  5  6  7  8  9  10 |
| rating                        |
| 1  2  3  4  5  6  7  8  9  10 |
| rating                        |
| rating                        |
| f                             |
| absolutely                    |
| great                         |
| bad                           |
1  2  3  4  5  6  7  8  9  10
1  2  3  4 
Cat
rating
1  2  3  4  5  6  7  8  9  10
1  2  3  4  5  6  7  8  9  10
rating
rating
p
utterly
excellent
terrible
1  2  3  4  5  6  7  8  9  10
1  2  3  4
-0.50
-0.39
-0.28

Fig. 21.11 shows the Potts diagrams for emphasizing and attenuating adverbs.

Note that emphatics tend to have a J-shape (most likely to occur in the most positive reviews) or a U-shape (most likely to occur in the strongly positive and negative). Attenuators all have the hump-shape, emphasizing the middle of the scale and downplaying both extremes. The diagrams can be used both as a typology of lexical sentiment, and also play a role in modeling sentiment compositionality.

In addition to functions like posterior P(c|w), likelihood P(w|c), or normalized likelihood (Eq. 21.6) many other functions of the count of a word occurring with a sentiment label have been used. We'll introduce some of these on page 16, including ideas like normalizing the counts per writer in Eq. 21.14.

## 21.5.1 Log Odds Ratio Informative Dirichlet Prior

One thing we often want to do with word polarity is to distinguish between words that are more likely to be used in one category of texts than in another. We may, for example, want to know the words most associated with 1 star reviews versus those associated with 5 star reviews. These differences may not be just related to sentiment. We might want to find words used more often by Democratic than Republican

fairly/r

## 21.5 - Supervised Learning Of Word Sentiment 13

"Potts&diagrams"
Potts,&Christopher.& 2011.&NSF&workshop&on& restructuring&adjectives.

ve scalars
Negative scalars
Emphatics
Attenuators
totally
good
disappointing
1  2  3  4  5  6  7  8  9  10
 5  6  7  8  9  10
rating
rating
fairly
absolutely
great
pretty/r
bad

members of Congress, or words used more often in menus of expensive restaurants than cheap restaurants.

Given two classes of documents, to find words more associated with one category than another, we could measure the difference in frequencies (is a word w more frequent in class A or class B?). Or instead of the difference in frequencies we could compute the ratio of frequencies, or compute the log odds ratio (the log of the ratio between the odds of the two words). We could then sort words by whichever association measure we pick, ranging from words overrepresented in category A to words overrepresented in category B.

The problem with simple log-likelihood or log odds methods is that they overemphasize differences in very rare words, and often also in very frequent words. Very rare words will seem to occur very differently in the two corpora since with tiny counts there may be statistical fluctations, or even zero occurrences in one corpus compared to non-zero occurrences in the other. Very frequent words will also seem different since all counts are large.

In this section we walk through the details of one solution to this problem: the
"log odds ratio informative Dirichlet prior" method of Monroe et al. (2008) that is a particularly useful method for finding words that are statistically overrepresented in one particular category of texts compared to another. It's based on the idea of using another large corpus to get a prior estimate of what we expect the frequency of each word to be.

Let's start with the goal: assume we want to know whether the word horrible occurs more in corpus i or corpus j. We could compute the **log likelihood ratio**, log likelihood ratio using f i(w) to mean the frequency of word w in corpus i, and ni to mean the total number of words in corpus i:

$$\mbox{ltr}(horrible)=\log\frac{P^{i}(horrible)}{P^{j}(horrible)}\tag{21.7}$$ $$=\log P^{j}(horrible)-\log P^{j}(horrible)$$ $$=\log\frac{\mbox{f}^{i}(horrible)}{n^{i}}-\log\frac{\mbox{f}^{j}(horrible)}{n^{j}}$$
Instead, let's compute the **log odds ratio**: does *horrible* have higher odds in i or in log odds ratio j:

lor(*horrible*) = log  Pi(*horrible*)  −log  Pj(*horrible*)

1−Pi(*horrible*) 1−Pj(*horrible*) fi(*horrible*) f j(*horrible*) ni n j = log     ni nj 1− fi(*horrible*) 1− fj(*horrible*)    −log     (21.8) = log  fi(*horrible*)  −log  f j(*horrible*)

ni −fi(*horrible*) nj −fj(*horrible*)
The Dirichlet intuition is to use a large background corpus to get a prior estimate of what we expect the frequency of each word w to be. We'll do this very simply by adding the counts from that corpus to the numerator and denominator, so that we're essentially shrinking the counts toward that prior. It's like asking how large are the differences between i and j given what we would expect given their frequencies in a well-estimated large background corpus.

The method estimates the difference between the frequency of word w in two corpora i and j via the prior-modified log odds ratio for w, δ (i−j)
w
, which is estimated as:

(21.9)   f j w +αw ! δ (i−j) w = log  f i w +αw  −log ni +α0 −(f iw +αw) nj +α0 −( f j w +αw)
(where ni is the size of corpus i, nj is the size of corpus j, f i w is the count of word w in corpus i, f j w is the count of word w in corpus j, α0 is the scaled size of the background corpus, and αw is the scaled count of word w in the background corpus.)
In addition, Monroe et al. (2008) make use of an estimate for the variance of the log–odds–ratio:

(21.10) f iw +αw + 1 f j w +αw σ2  ˆδ (i− j) w  ≈ 1
The final statistic for a word is then the z–score of its log–odds–ratio:

ˆδ (i−j) w r σ2  ˆδ (i−j) w  (21.11)
The Monroe et al. (2008) method thus modifies the commonly used log odds ratio in two ways: it uses the z-scores of the log odds ratio, which controls for the amount of variance in a word's frequency, and it uses counts from a background corpus to provide a prior count for words.

Fig. 21.12 shows the method applied to a dataset of restaurant reviews from Yelp, comparing the words used in 1-star reviews to the words used in 5-star reviews (Jurafsky et al., 2014). The largest difference is in obvious sentiment words, with the 1-star reviews using negative sentiment words like *worse, bad, awful* and the 5-star reviews using positive sentiment words like *great, best, amazing*. But there are other illuminating differences. 1-star reviews use logical negation (*no, not*), while 5-star reviews use emphatics and emphasize universality (*very, highly, every, always*). 1-
star reviews use first person plurals (*we, us, our*) while 5 star reviews use the second person. 1-star reviews talk about people (*manager, waiter, customer*) while 5-star reviews talk about dessert and properties of expensive restaurants like courses and atmosphere. See Jurafsky et al. (2014) for more details.

| Class                                      |
|--------------------------------------------|
| Positive                                   |
| great, best, love(d), delicious, amazing,  |
| favorite, perfect, excellent, awesome,     |
| friendly, fantastic, fresh, wonderful, in- |
| credible, sweet, yum(my)                   |
| Negative                                   |
| worst, rude, terrible, horrible, bad,      |
| awful, disgusting, bland, tasteless,       |
| gross, mediocre, overpriced, worse,        |
| poor                                       |
| Negation                                   |
| no, not                                    |
| Emphatics/                                 |
| universals                                 |
| very, highly, perfectly, definitely, abso- |
| lutely, everything, every, always          |
| 1Pl pro                                    |
| we, us, our                                |
| 2 pro                                      |
| you                                        |
| 3 pro                                      |
| she, he, her, him                          |
| Articles                                   |
| a, the                                     |
| Past verb                                  |
| was, were, asked, told, said, did,         |
| charged, waited, left, took                |
| Advice                                     |
| try, recommend                             |
| Sequencers                                 |
| after, then                                |
| Conjunct                                   |
| also, as, well, with, and                  |
| Nouns                                      |
| atmosphere, dessert, chocolate, wine,      |
| course, menu                               |
| Nouns                                      |
| manager, waitress, waiter, customer,       |
| customers, attitude, waste, poisoning,     |
| money, bill, minutes                       |
| Irrealis                                   |
| modals                                     |
| would, should                              |
| Auxiliaries                                |
| is/'s, can, 've, are                       |
| Comp                                       |
| to, that                                   |
| Prep, other                                |
| in, of, die, city, mouth                   |

## 21.6 Using Lexicons For Sentiment Recognition

In Chapter 4 we introduced the naive Bayes algorithm for sentiment analysis. The lexicons we have focused on throughout the chapter so far can be used in a number of ways to improve sentiment detection.

In the simplest case, lexicons can be used when we don't have sufficient training data to build a supervised sentiment analyzer; it can often be expensive to have a human assign sentiment to each document to train the supervised classifier.

In such situations, lexicons can be used in a rule-based algorithm for classification. The simplest version is just to use the ratio of positive to negative words: if a document has more positive than negative words (using the lexicon to decide the polarity of each word in the document), it is classified as positive. Often a threshold λ
is used, in which a document is classified as positive only if the ratio is greater than
λ. If the sentiment lexicon includes positive and negative weights for each word, θ +
w and θ −
w , these can be used as well. Here's a simple such sentiment algorithm:

w s.t. w∈positivelexicon θ + w *count*(w) f + = X w s.t. w∈negativelexicon θ − w *count*(w) f − = X + if f + f − > λ (21.12) sentiment = f + > λ − if f −      0 otherwise.    
If supervised training data is available, these counts computed from sentiment lexicons, sometimes weighted or normalized in various ways, can also be used as features in a classifier along with other lexical or non-lexical features. We return to such algorithms in Section 21.7.

## 21.7 Using Lexicons For Affect Recognition

Detection of emotion (and the other kinds of affective meaning described by Scherer (2000)) can be done by generalizing the algorithms described above for detecting sentiment.

The most common algorithms involve supervised classification: a training set is labeled for the affective meaning to be detected, and a classifier is built using features extracted from the training set. As with sentiment analysis, if the training set is large enough, and the test set is sufficiently similar to the training set, simply using all the words or all the bigrams as features in a powerful classifier like SVM or logistic regression, as described in Fig. ?? in Chapter 4, is an excellent algorithm whose performance is hard to beat. Thus we can treat affective meaning classification of a text sample as simple document classification.

Some modifications are nonetheless often necessary for very large datasets. For example, the Schwartz et al. (2013) study of personality, gender, and age using 700 million words of Facebook posts used only a subset of the n-grams of lengths 1- 3. Only words and phrases used by at least 1% of the subjects were included as features, and 2-grams and 3-grams were only kept if they had sufficiently high PMI
(PMI greater than 2∗*length*, where *length* is the number of words):

$\mathrm{pmi}(phrase)=\log\frac{p(phrase)}{\prod_{w\in phrase}p(w)}$ (21.13)
Various weights can be used for the features, including the raw count in the training set, or some normalized probability or log probability. Schwartz et al. (2013), for example, turn feature counts into phrase likelihoods by normalizing them by each subject's total word use.

$$p(phrase|subject)=\frac{\text{freq}(phrase,subject)}{\sum_{\text{freq}(phrase^{\prime},subject)}}\tag{21.14}$$
If the training data is sparser, or not as similar to the test set, any of the lexicons we've discussed can play a helpful role, either alone or in combination with all the words and n-grams.

Many possible values can be used for lexicon features. The simplest is just an indicator function, in which the value of a feature fL takes the value 1 if a particular text has any word from the relevant lexicon L. Using the notation of Chapter 4, in which a feature value is defined for a particular output class c and document x.

$f_{L}(c,x)=\left\{\begin{array}{ll}1&\mbox{if}\exists w:w\in L\ \&\ w\in x\ \&\ class=c\\ 0&\mbox{otherwise}\end{array}\right.$
Alternatively the value of a feature fL for a particular lexicon L can be the total number of word *tokens* in the document that occur in L:

$$f_{L}=\sum_{w\in L}c o u m(w)$$
For lexica in which each word is associated with a score or weight, the count can be multiplied by a weight θ L
w:

$$f_{L}=\sum_{w\in L}\theta_{w}^{L}c o u n t(w)$$
Counts can alternatively be logged or normalized per writer as in Eq. 21.14.

However they are defined, these lexicon features are then used in a supervised classifier to predict the desired affective category for the text or document. Once a classifier is trained, we can examine which lexicon features are associated with which classes. For a classifier like logistic regression the feature weight gives an indication of how associated the feature is with the class.

## 21.8 Lexicon-Based Methods For Entity-Centric Affect

What if we want to get an affect score not for an entire document, but for a particular entity in the text? The entity-centric method of Field and Tsvetkov (2019) combines affect lexicons with contextual embeddings to assign an affect score to an entity in text. In the context of affect about people, they relabel the Valence/Arousal/Dominance dimension as Sentiment/Agency/Power. The algorithm first trains classifiers to map embeddings to scores:

1. For each word w in the training corpus:
(a) Use off-the-shelf pretrained encoders (like BERT) to extract a contextual
embedding e for each instance of the word. No additional fine-tuning is
done.
(b) Average over the e embeddings of each instance of w to obtain a single
embedding vector for one training point w.
(c) Use the NRC VAD Lexicon to get S, A, and P scores for w.
2. Train (three) regression models on all words w to predict V, A, D scores from
a word's average embedding.
Now given an entity mention m in a text, we assign affect scores as follows:

1. Use the same pretrained LM to get contextual embeddings for m in context. 2. Feed this embedding through the 3 regression models to get S, A, P scores for
the entity.
This results in a (S,A,P) tuple for a given entity mention; To get scores for the representation of an entity in a complete document, we can run coreference resolution and average the (S,A,P) scores for all the mentions. Fig. 21.13 shows the scores from their algorithm for characters from the movie *The Dark Knight* when run on Wikipedia plot summary texts with gold coreference.

Rachel
Rachel

high sentiment.

terns as the regression model with greater between characters.

## 21.9 Connotation Frames

ment have resulted in his effective removal from the industry.

While articles about the #MeToo The lexicons we've described so far define a word as a point in affective space. A
connotation frame, by contrast, is a lexicon that incorporates a richer kind of gramconnotation frame movement portray men like Weinstein as unpowerful, we can speculate that the corpora used to train ELMo and BERT portray them as powerful.

Thus, in a corpus where traditional power roles matical structure, by combining affective lexicons with the frame semantic lexicons of Chapter 24. The basic insight of connotation frame lexicons is that a predicate like a verb expresses connotations about the verb's arguments (Rashkin et al. 2016, Rashkin et al. 2017).

Consider sentences like:

(21.15) Country A violated the sovereignty of Country B (21.16) the teenager ... survived the Boston Marathon bombing"
vey Dent (ally to Batman who turns Rachel Dawes (primary love interest). itate extracting example sentences, we instance of these entities in the narrative and average across instances to obtain score for the document.9 To maximiz by capturing every mention of an entit form co-reference resolution by hand. ally, based on our results from Table 3 the use of Wikipedia data in training model (Peters et al., 2018), we use ELM dings for our analysis.

Figures 1 and 2 show results.

By using the verb *violate* in (21.15), the author is expressing their sympathies with Country B, portraying Country B as a victim, and expressing antagonism toward the agent Country A. By contrast, in using the verb *survive*, the author of (21.16) is expressing that the bombing is a negative experience, and the subject of the sentence, the teenager, is a sympathetic character. These aspects of connotation are inherent in the meaning of the verbs *violate* and *survive*, as shown in Fig. 21.14.

The connotation frame lexicons of Rashkin et al. (2016) and Rashkin et al.

ence, we show the entity scores as co one polar opposite pair identified by the regression model and ASP show s terns. Batman has high power, while R low power. Additionally, the Joker is with the most negative sentiment, but est agency.

Throughout the plot sum have been inverted, the embeddings extracted from ELMo and BERT perform worse than random, as they are biased towards the power structures in the data they are trained on. Further evidence of this exists in the performance of the BERT-masked embeddings - whereas these embeddings generally capture power poorly as compared to the unmasked embeddings (Table 2), they outperform the unmasked embeddings on this task, and even outperform the frequency baseline in one setting. Nevertheless, they do not outperform Field et al. (2019), likely because they do not capture affect information as well as the unmasked embeddings (Table 2).

## 4.3 Qualitative Document-Level Analysis

(2017) also express other connotative aspects of the predicate toward each argument, including the *effect* (something bad happened to x) *value*: (x is valuable), and mental state: (x is distressed by the event). Connotation frames can also mark the power differential between the arguments (using the verb *implore* means that the theme argument has greater power than the agent), and the *agency* of each argument (*waited* is low agency). Fig. 21.15 shows a visualization from Sap et al. (2017).

Connotation frames can be built by hand (Sap et al., 2017), or they can be learned by supervised learning (Rashkin et al., 2016), for example using hand-labeled training data to supervise classifiers for each of the individual relations, e.g., whether S(writer → Role1) is + or -, and then improving accuracy via global constraints across all relations.

movie progresses by the Joker taking sive action and the other characters r We can see this dynamic reflected in t profile score, as a high-powered, hi low-sentiment character, who is the pri driver. In general, ASP shows a greater between characters than the regression hypothesize that this occurs because A the dimensions of interest, while the reg proach captures other confounds, such Finally, we qualitatively analyze how well our method captures affect dimensions by analyzing single documents in detail. We conduct this analysis in a domain where we expect entities to fulfill traditional power roles and where entity portrayals are known. Following Bamman et al. (2013), we analyze the Wikipedia plot summary of the movie *The Dark Knight*,7 focusing on Batman (protagonist),8 the Joker (antagonist), Jim Gordan
(law enforcement officer, ally to Batman), Har-

## 21.10 Summary

Figure 3: Sample verbs in the connotation frame with high annotator agreement. Size is indicativ of verb frequency in our corpus (bigger = mor frequent), color differences are only for legibility

- Many kinds of affective states can be distinguished, including emotions, *moods*,
attitudes (which include sentiment), *interpersonal stance*, and *personality*.
Figure 2: The formal notation of the connotation frames of power and agency. The first example shows the relative power differential implied by the verb **"implored"**, i.e., the agent ("he") is in a position of less power than the theme ("the tribunal"). In contrast, "He **demanded** the tribunal show mercy" implies that the agent has authority over the theme. The second example shows the low level of agency implied by the verb **"waited"**.

one another.

For example, if the agent "dom

- **Emotion** can be represented by fixed atomic units often called basic emotions, or as points in space defined by dimensions like **valence** and **arousal**.
- Words have **connotational** aspects related to these affective states, and this
connotational aspect of word meaning can be represented in lexicons.
- Affective lexicons can be built by hand, using **crowd sourcing** to label the
affective content of each word.
interactive demo website of our findings (see Figure 5 in the appendix for a screenshot).2 Furthermore, as will be seen in Section 4.1, connotation frames offer new insights that complement and deviate from the well-known Bechdel test (Bechdel, 1986).

In particular, we find that high-agency

- Lexicons can be built with **semi-supervised**, bootstrapping from seed words
using similarity metrics like embedding cosine.
inates" the theme (denoted as *power*(AG>TH) then the agent is implied to have a level of contro over the theme. Alternatively, if the agent "hon ors" the theme (denoted as *power*(AG<TH)), th writer implies that the theme is more important o authoritative. We used AMT crowdsourcing to la bel 1700 transitive verbs for power differential With three annotators per verb, the inter-annotato agreement is 0.34 (Krippendorff's ↵).

Agency The agency attributed to the agent of th

- Lexicons can be learned in a **fully supervised** manner, when a convenient
training signal can be found in the world, such as ratings assigned by users on a review site.
women through the lens of connotation frames are rare in modern films. It is, in part, because some movies (e.g., Snow White) accidentally pass the Bechdel test and also because even movies with strong female characters are not entirely free from the deeply ingrained biases in social norms.

- Words can be assigned weights in a lexicon by using various functions of word
counts in training texts, and ratio metrics like log odds ratio informative Dirichlet prior.
2
Connotation Frames of Power and
Agency
- Affect can be detected, just like sentiment, by using standard supervised text
classification techniques, using all the words or bigrams in a text as features.
We create two new connotation relations, power and *agency* (examples in Figure 3), as an expansion of the existing connotation frame lexicons.3
verb denotes whether the action being describe implies that the agent is powerful, decisive, an capable of pushing forward their own storylin For example, a person who is described as "ex periencing" things does not seem as active and de cisive as someone who is described as "determin ing" things. AMT workers labeled 2000 trans tive verbs for implying high/moderate/low agenc (inter-annotator agreement of 0.27). We denot high agency as *agency*(AG)=+, and low agenc as *agency*(AG)=−.

Three AMT crowdworkers annotated the verbs with placeholders to avoid gender bias in the context (e.g., X *rescued* Y; an example task is shown in the appendix in Figure 7). We define the anno-
Pairwise agreements on a hard constraint ar

Additional features can be drawn from counts of words in lexicons.

- Lexicons can also be used to detect affect in a **rule-based classifier** by picking
the simple majority sentiment based on counts of words in each lexicon.
- **Connotation frames** express richer relations of affective meaning that a predicate encodes about its arguments.

## Bibliographical And Historical Notes

The idea of formally representing the subjective meaning of words began with Osgood et al. (1957), the same pioneering study that first proposed the vector space model of meaning described in Chapter 6. Osgood et al. (1957) had participants rate words on various scales, and ran factor analysis on the ratings. The most significant factor they uncovered was the evaluative dimension, which distinguished between pairs like good/bad, valuable/worthless, *pleasant/unpleasant*. This work influenced the development of early dictionaries of sentiment and affective meaning in the field of **content analysis** (Stone et al., 1966).

Wiebe (1994) began an influential line of work on detecting **subjectivity** in text, subjectivity beginning with the task of identifying subjective sentences and the subjective characters who are described in the text as holding private states, beliefs or attitudes. Learned sentiment lexicons such as the polarity lexicons of Hatzivassiloglou and McKeown (1997) were shown to be a useful feature in subjectivity detection (Hatzivassiloglou and Wiebe 2000, Wiebe 2000).

The term **sentiment** seems to have been introduced in 2001 by Das and Chen
(2001), to describe the task of measuring market sentiment by looking at the words in stock trading message boards. In the same paper Das and Chen (2001) also proposed the use of a sentiment lexicon. The list of words in the lexicon was created by hand, but each word was assigned weights according to how much it discriminated a particular class (say buy versus sell) by maximizing across-class variation and minimizing within-class variation. The term *sentiment*, and the use of lexicons, caught on quite quickly (e.g., inter alia, Turney 2002). Pang et al. (2002) first showed the power of using all the words without a sentiment lexicon; see also Wang and Manning (2012).

Most of the semi-supervised methods we describe for extending sentiment dictionaries drew on the early idea that synonyms and antonyms tend to co-occur in the same sentence (Miller and Charles 1991, Justeson and Katz 1991, Riloff and Shepherd 1997). Other semi-supervised methods for learning cues to affective meaning rely on information extraction techniques, like the AutoSlog pattern extractors (Riloff and Wiebe, 2003). Graph based algorithms for sentiment were first suggested by Hatzivassiloglou and McKeown (1997), and graph propagation became a standard method (Zhu and Ghahramani 2002, Zhu et al. 2003, Zhou et al. 2004, Velikovich et al. 2010). Crowdsourcing can also be used to improve precision by filtering the result of semi-supervised lexicon learning (Riloff and Shepherd 1997, Fast et al. 2016).

Much recent work focuses on ways to learn embeddings that directly encode sentiment or other properties, such as the DENSIFIER algorithm of Rothe et al. (2016)
that learns to transform the embedding space to focus on sentiment (or other) information.
